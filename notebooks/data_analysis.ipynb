{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "This notebook is devoted to the analysis of the DWAVE data and the comparison between them and the data generated by the Neural Network (MADE for the moment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from typing import Sequence, List, Optional\n",
    "\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.smart_montecarlo import mcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def econf(Lx: int, J: np.ndarray, S0: np.ndarray) -> float:\n",
    "    energy = 0.\n",
    "    for kx in range(Lx):\n",
    "        for ky in range(Lx):\n",
    "\n",
    "            k = kx + (Lx * ky)\n",
    "            R = kx + 1  # right spin\n",
    "            D = ky + 1  # down spin\n",
    "\n",
    "            kR = k - ky  # coupling to the right of S0[kx,ky]\n",
    "            kD = k  # coupling to the down of S0[kx,ky]\n",
    "\n",
    "            # Tries to find a spin to right, if no spin, contribution is 0.\n",
    "            Rs = S0[R, ky] * J[kR, 0] if R % Lx != 0 else 0\n",
    "            # Tries to find a spin to left, if no spin, contribution is 0.\n",
    "            Ds = S0[kx, D] * J[kD, 1] if D % Lx != 0 else 0\n",
    "\n",
    "            energy += -S0[kx, ky] * (Rs + Ds)\n",
    "    return energy / (Lx**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coupling_open(Lx: int = 22, seed: int = 12345):\n",
    "    np.random.seed(seed)\n",
    "    N=Lx**2\n",
    "    return (np.random.normal(0.0, 1.0, size=(N - Lx, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(gen_paths: Sequence[str], truth_path: str = \"/home/scriva/pixel-cnn/data/100-v1/train_100_lattice_2d_ising_spins.npy\", seed: int = 12345, labels: Optional[List[str]] = None, save: bool = False) -> None:\n",
    "    if labels is None:\n",
    "        labels = [f\"eng{i}\" for i, _ in enumerate(gen_paths)]\n",
    "\n",
    "    truth = np.load(truth_path)\n",
    "    \n",
    "    try:\n",
    "        truth = truth[\"sample\"]\n",
    "    except:\n",
    "        print(f\"No sample subdir found in {truth_path} \\nLoading from path...\")\n",
    "        truth = truth\n",
    "\n",
    "    truth = np.reshape(truth, (-1, int(sqrt(truth.shape[-1])), int(sqrt(truth.shape[-1]))), order='F')\n",
    "    max_len_sample = truth.shape[0]\n",
    "    square_spin = truth.shape[-1]\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    J = get_coupling_open(Lx=square_spin, seed=seed) # (square_spin, seed=seed)\n",
    "\n",
    "    eng_truth = []\n",
    "    for t in truth:\n",
    "        eng_truth.append(econf(square_spin, J, t))\n",
    "    eng_truth = np.asarray(eng_truth)\n",
    "    \n",
    "    engs= []\n",
    "    for path in gen_paths:\n",
    "        out = np.load(path)\n",
    "\n",
    "        try:\n",
    "            sample = out[\"sample\"]\n",
    "        except:\n",
    "            print(f\"No sample subdir found in {path} \\nLoading from path...\")\n",
    "            sample = out\n",
    "        \n",
    "        sample = sample.squeeze()\n",
    "        max_len_sample = min(max_len_sample, sample.shape[0])\n",
    "        sample = np.reshape(sample, (-1, square_spin, square_spin), order='F')\n",
    "\n",
    "        eng = []\n",
    "        for s in sample:\n",
    "            eng.append(econf(square_spin, J, s))\n",
    "        eng = np.asarray(eng)\n",
    "\n",
    "        engs.append(eng)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8), facecolor='white')\n",
    "    \n",
    "    plt.rcParams['mathtext.fontset']= \"stix\"\n",
    "    plt.rcParams['font.family']= 'STIXGeneral'\n",
    "\n",
    "    stringfont = 'serif'\n",
    "\n",
    "    plt.tick_params(axis='y',labelsize=12)\n",
    "    plt.tick_params(axis='x',labelsize=12)\n",
    "    \n",
    "    bins = np.linspace(eng_truth.min(),engs[0].max()).tolist()\n",
    "\n",
    "    for i, eng in enumerate(engs):\n",
    "        _ = plt.hist(eng[:max_len_sample], bins=bins, log=True, label=f\"{labels[i]}\", alpha=0.8)\n",
    "        print(f\"\\neng {i}\\nmean: {eng.mean()}\\nmin: {eng.min()} ({np.sum(eng==eng.min())} time(s))\")\n",
    "    \n",
    "    _ = plt.hist(eng_truth[:max_len_sample], bins=bins, log=True, label=r\"DWave 2000$\\mu$s\", histtype='bar', ec='black', alpha=0.2)\n",
    "    print(f\"\\nDWave data eng\\nmean: {eng_truth.mean()}\\nmin: {eng_truth.min()}  ({np.sum(eng_truth==eng_truth.min())} time(s))\")\n",
    "\n",
    "    plt.ylabel(\"Count\", fontsize=18, fontfamily=stringfont)\n",
    "    plt.xlabel(r\"$\\frac{E}{N}$\", fontsize=18, fontfamily=stringfont)\n",
    "\n",
    "    plt.ylim(1, max_len_sample)\n",
    "    plt.legend(loc='best', labelspacing=0.4, fontsize=14, borderpad=0.2)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"hist.png\", edgecolor='white', facecolor=fig.get_facecolor(), bbox_inches='tight')\n",
    "\n",
    "    return engs, eng_truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check energy\n",
    "\n",
    "Load dataset as it is saved by [DWAVE system](https://cloud.dwavesys.com/leap/login/?next=/leap/). Since there is a maximum time for the annealing process, data are saved in files with maximum size of 10k sample. In the same folder one can find also two energy file, one computed directly by DWAVE annealer and the other one with our custom algorithm. Both should give us the same result. So, here we load the dataset and we rearrange them in two files, namely train and validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(f'configs_*')\n",
    "#print(files)\n",
    "\n",
    "arrs = []\n",
    "for file in files:\n",
    "    arrs.append(np.load(file))\n",
    "dataset = np.concatenate(arrs, axis=0)\n",
    "print(dataset.shape)\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.15)\n",
    "\n",
    "# Comment off the following lines to save the datasets.\n",
    "# np.save('DWAVE-train-484spins-1nn-100mu', train_data)\n",
    "# np.save('DWAVE-test-484spins-1nn-100mu', test_data)\n",
    "np.save(\"1000mu\", dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we load a small part of the original dataset in order to check if the energy is well computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.load(\"../data/1-50k_open-simple_10mu/configs_0.npy\")\n",
    "dwave_eng = np.load(\"../data/1-50k_open-simple_10mu/dwave-engs_0.npy\")\n",
    "eng = np.loadtxt(\"../data/1-50k_open-simple_10mu/energies_0.txt\")\n",
    "\n",
    "print(f\"Energy (from DWAVE) {dwave_eng[:4]}\\nEnergy (our algo) {-eng[:4]*484}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot histograms\n",
    "\n",
    "Here we want to check if the Neural Network has been well trained, a good measure could also be the mean energy of the DWAVE data and the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=[\"data/datasets/484-1nn-10mu/DWAVE-test-484spins-10mu.npy\", \"data/datasets/484-1nn-50mu/DWAVE-test-484spins-50mu.npy\", \"data/datasets/484-1nn-100mu/DWAVE-test-484spins-1nn-100mu.npy\"]  #[\"/home/beppe/neural-mcmc/sample-100000_size-484_2021-11-15_14_31_46.npz\"]\n",
    "labels = [r\"Dwave 10$\\mu$s\", r\"Dwave 50$\\mu$s\", r\"Dwave 100$\\mu$s\", r\"NN Re-Weighted\",]\n",
    "truth = \"/home/beppe/neural-mcmc/2000mu.npy\" #\"/home/beppe/neural-mcmc/data/datasets/484-1nn-100mu/DWAVE-train-484spins-1nn-100mu.npy\"\n",
    "engs, eng_truth = plot_hist(path, truth_path=truth, labels=labels, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Results with Trained MADE on DWave Data\n",
    "\n",
    "Computing the acceptance rate for some $\\beta \\in (0,5)$ we can notice that it exists an effective $\\beta$, let's call it $\\beta_{eff}$ that is increasing according to the annealing time selected in the D-Wave machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"/home/beppe/neural-mcmc/data/generated/size-484_sample-100000_2.npz\", \"/home/beppe/neural-mcmc/data/generated/size-484_sample-100000_09-05-10.npz\"]\n",
    "            #\"size-10_sample-100001_nade.npz\",\n",
    "            #\"size-100_sample-100001_1p8bmv7t.npz\",]\n",
    "betas = np.arange(0.1, 3., step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rates = []\n",
    "for dataset in tqdm(datasets, leave=True):\n",
    "    acc_rate = []\n",
    "    for beta in betas:\n",
    "        ar = mcmc(beta, 50000, dataset)\n",
    "        acc_rate.append(ar)\n",
    "    acc_rates.append(acc_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8), facecolor='white')\n",
    "\n",
    "plt.rcParams['mathtext.fontset']= \"stix\"\n",
    "plt.rcParams['font.family']= 'STIXGeneral'\n",
    "\n",
    "stringfont = 'serif'\n",
    "\n",
    "plt.tick_params(axis='y', labelsize=10)\n",
    "plt.tick_params(axis='x', labelsize=10)\n",
    "\n",
    "ax.set_xticklabels([r'0', r'0.5', r'1',r'1.5',r'2',r'2.5',r'3'], fontsize=12, fontfamily=stringfont)\n",
    "ax.set_yticklabels([r'0',r'1',r'2',r'3',r'4',r'5'], fontsize=12, fontfamily=stringfont)\n",
    "\n",
    "plt.tick_params(top=True, right=True, labeltop=False, labelright=False, direction='in')\n",
    "plt.tick_params(top=True, right=True, labeltop=False, labelright=False, direction='in')\n",
    "\n",
    "labels = [r\"10 $\\mu$s\",r\"50 $\\mu$s\"]\n",
    "\n",
    "for i, acc_rate in enumerate(acc_rates):\n",
    "    plt.plot(betas, acc_rate, \"-.\", label=labels[i])#, linewidth=3.)\n",
    "\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,5)\n",
    "\n",
    "plt.ylabel(r\"$\\mathrm{A_r}$[%]\", fontsize=18, fontfamily=stringfont)\n",
    "plt.xlabel(r\"$\\mathrm{\\beta}$\", fontsize=18, fontfamily=stringfont)\n",
    "\n",
    "plt.legend(loc='best', fontsize=18, labelspacing=0.4, borderpad=0.2)\n",
    "\n",
    "plt.savefig(\"ar-vs-beta.png\", edgecolor='white', facecolor=fig.get_facecolor(), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44e32361504ecffb4069183ffd9479e020b26ae773c88426990cda2749af0a19"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('test': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
